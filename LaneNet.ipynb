{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "434396fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 12:31:24.737684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846fa0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_input_layer(input_shape=(80, 160, 3)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    return inputs\n",
    "\n",
    "# Define the LaneNet-like model\n",
    "def LaneNet(input_shape=(80, 160, 3)):\n",
    "    inputs = custom_input_layer(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "# Create the LaneNet model with input size (80, 160, 3)\n",
    "model = LaneNet(input_shape=(80, 160, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b22abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "69/69 [==============================] - 212s 3s/step - loss: 0.1600 - accuracy: 0.8207 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 209s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 209s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 209s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 209s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 208s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 209s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 206s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 208s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 208s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 210s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 213s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 209s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 209s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 209s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 210s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 210s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 209s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 19/20\n",
      "69/69 [==============================] - 211s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n",
      "Epoch 20/20\n",
      "69/69 [==============================] - 210s 3s/step - loss: 0.1534 - accuracy: 0.8287 - val_loss: 0.1523 - val_accuracy: 0.8298\n"
     ]
    }
   ],
   "source": [
    "    # Load training images\n",
    "    train_images = pickle.load(open(\"full_CNN_train.p\", \"rb\" ))\n",
    "\n",
    "    # Load image labels\n",
    "    labels = pickle.load(open(\"full_CNN_labels.p\", \"rb\" ))\n",
    "\n",
    "    # Make into arrays as the neural network wants these\n",
    "    train_images = np.array(train_images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Normalize labels - training images get normalized to start in the network\n",
    "    labels = labels / 255\n",
    "\n",
    "    # Shuffle images along with their labels, then split into training/validation sets\n",
    "    train_images, labels = shuffle(train_images, labels)\n",
    "    # Test size may be 10% or 20%\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_images, labels, test_size=0.3)\n",
    "\n",
    "    # Batch size, epochs and pool size below are all paramaters to fiddle with for optimization\n",
    "    batch_size = 128\n",
    "    epochs = 20 \n",
    "    pool_size = (2, 2)\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    # Create the neural network\n",
    "    model = LaneNet(input_shape)\n",
    "\n",
    "    # Using a generator to help the model use less data\n",
    "    # Channel shifts help with shadows slightly\n",
    "    datagen = ImageDataGenerator(channel_shift_range=0.2)\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Compiling and training the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
    "    model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=len(X_train)/batch_size,\n",
    "    epochs=epochs, verbose=1, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Freeze layers since training is done\n",
    "    model.trainable = False\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
    "\n",
    "    # Save model architecture and weights\n",
    "    model.save('Lane_Net_new_model.keras')\n",
    "    \n",
    "    #save model architecture in json file\n",
    "    model_json = model.to_json()\n",
    "    with open(\"lane_Net_model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b157d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 80, 160, 3)]      0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 80, 160, 64)       1792      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 40, 80, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 40, 80, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 20, 40, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSamplin  (None, 40, 80, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 40, 80, 64)        73792     \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSamplin  (None, 80, 160, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 80, 160, 1)        577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150017 (586.00 KB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 150017 (586.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb29053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 15s 126ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score,recall_score,f1_score,accuracy_score\n\u001b[1;32m      4\u001b[0m predicted_labels\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m----> 6\u001b[0m accuracy\u001b[38;5;241m=\u001b[39m accuracy_score(y_val,predicted_labels)\n\u001b[1;32m      7\u001b[0m precision\u001b[38;5;241m=\u001b[39m precision_score(y_val,predicted_labels)\n\u001b[1;32m      8\u001b[0m recall\u001b[38;5;241m=\u001b[39m recall_score(y_val,predicted_labels)\n",
      "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/sklearn/metrics/_classification.py:104\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    107\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: unknown is not supported"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "\n",
    "predicted_labels= model.predict(X_val)\n",
    "\n",
    "accuracy= accuracy_score(y_val,predicted_labels)\n",
    "precision= precision_score(y_val,predicted_labels)\n",
    "recall= recall_score(y_val,predicted_labels)\n",
    "f1= f1_score(y_val,predicted_labels)\n",
    "\n",
    "print(f\"accuracy:{accuracy:.4f}\")\n",
    "print(f\"precision:{precision:.4f}\")\n",
    "print(f\"recall:{recall:.4f}\")\n",
    "print(f\"F1_score:{f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5030e847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 15s 125ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m predicted_labels_binary \u001b[38;5;241m=\u001b[39m (predicted_labels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate and plot the confusion matrix\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_val\u001b[38;5;241m.\u001b[39mflatten(), predicted_labels_binary\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Plot the confusion matrix\u001b[39;00m\n\u001b[1;32m     16\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(conf_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m, cbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "predicted_labels= model.predict(X_val)\n",
    "\n",
    "# Convert predicted labels to binary format (0 or 1) using a threshold (e.g., 0.5)\n",
    "predicted_labels_binary = (predicted_labels > 0.5).astype(int)\n",
    "\n",
    "# Calculate and plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val.flatten(), predicted_labels_binary.flatten())\n",
    "\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_val.flatten(), predicted_labels_binary.flatten())\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example continuous and binary targets (replace with your actual data)\n",
    "train_images = np.random.rand(100)  # Continuous values between 0 and 1\n",
    "binarydnp.random.rand(100) > 0.5).astype(int)  # Binary labels (0 or 1)\n",
    "\n",
    "# Assuming 'continuous_targets' and 'binary_targets' are your actual targets\n",
    "# Replace them with your own data\n",
    "\n",
    "# Convert continuous targets to binary using a threshold\n",
    "threshold = 0.5  # Adjust the threshold as needed\n",
    "predicted_binary = (continuous_targets > threshold).astype(int)\n",
    "\n",
    "# Calculate the confusion matrix for binary classification\n",
    "conf_matrix_binary = confusion_matrix(binary_targets, predicted_binary)\n",
    "\n",
    "# Plot the confusion matrix for binary classification\n",
    "sns.heatmap(conf_matrix_binary, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel('Predicted Labels (Binary)')\n",
    "plt.ylabel('True Labels (Binary)')\n",
    "plt.title('Confusion Matrix (Binary Classification)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
